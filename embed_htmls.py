import os
import pandas as pd
import pdfplumber
import chromadb
from sentence_transformers import SentenceTransformer
from bs4 import BeautifulSoup

# âœ… ChromaDB ì„¤ì •
DB_PATH = "./chroma_db_v3"
COLLECTION_NAME = "company_docs"
DOCS_PATH = "./realizable_markdown"

# âœ… ChromaDB ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
chroma_client = chromadb.PersistentClient(path=DB_PATH)
collection = chroma_client.get_or_create_collection(name=COLLECTION_NAME)

# âœ… ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
model_1 = 'all-MiniLM-L6-v2'
model_2 = 'upstage/solar-embedding-1-large'
model_3 = 'bge-large-en' # ìµœê·¼ ì¸ê¸°, ê²€ìƒ‰ì— íŠ¹í™”ëœ ì„±ëŠ¥ ìš°ìˆ˜ ëª¨ë¸, ë‹¤ì†Œ ë¬´ê±°ì›€
model_4 = 'all-mpnet-base-v2' 
embedding_model = SentenceTransformer(model_4)

def extract_text_from_html(file_path):
    """ HTML íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ """
    with open(file_path, "r", encoding="utf-8") as f:
        soup = BeautifulSoup(f, "html.parser")
    return soup.get_text(separator=" ", strip=True)

def extract_text_from_csv(file_path):
    """ CSV íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ """
    try:
        df = pd.read_csv(file_path, encoding="utf-8")
    except UnicodeDecodeError:
        df = pd.read_csv(file_path, encoding="latin-1")

    text_data = df.astype(str).apply(lambda x: ' '.join(x.dropna()), axis=1).tolist()
    return " ".join(text_data)  # CSVì˜ ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ í•©ì¹¨

def extract_text_from_pdf(file_path):
    """ PDF íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ """
    text = []
    with pdfplumber.open(file_path) as pdf:
        for page in pdf.pages:
            text.append(page.extract_text() or "")
    return " ".join(text).strip()

def extract_text_from_md(file_path):
    """ Markdown (.md) íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ """
    with open(file_path, "r", encoding="utf-8") as f:
        text = f.read()
    return text.strip()  # ë¶ˆí•„ìš”í•œ ê³µë°± ì œê±°

def get_all_files(directory, extensions):
    """ íŠ¹ì • í™•ì¥ìì˜ íŒŒì¼ì„ ì¬ê·€ì ìœ¼ë¡œ ê²€ìƒ‰ """
    matched_files = []
    for root, _, files in os.walk(directory):
        for file in files:
            if file.endswith(extensions):
                matched_files.append(os.path.join(root, file))
    return matched_files

def embed_documents():
    """ HTML, CSV, PDF, Markdown ë¬¸ì„œë¥¼ ë²¡í„°ë¡œ ë³€í™˜í•˜ê³  ChromaDBì— ì €ì¥ """
    docs_path = DOCS_PATH
    # html_files = get_all_files(docs_path, (".html", ".htm"))
    # csv_files = get_all_files(docs_path, (".csv",))
    # pdf_files = get_all_files(docs_path, (".pdf",))
    md_files = get_all_files(docs_path, (".md",))  # âœ… Markdown íŒŒì¼ ì¶”ê°€

    # all_files = html_files + csv_files + pdf_files + md_files
    # if not all_files:
    #     print("âŒ No HTML, CSV, PDF, or Markdown files found in docs directory!")
    #     return

    print(f"ğŸ” Found {len(md_files)} files (HTML, CSV, PDF, Markdown). Processing...")

    for file_path in md_files:
        doc_id = os.path.basename(file_path)  # íŒŒì¼ëª…ì„ IDë¡œ ì‚¬ìš©

        # íŒŒì¼ ìœ í˜•ë³„ë¡œ ì²˜ë¦¬
        if file_path.endswith((".html", ".htm")):
            text = extract_text_from_html(file_path)
        elif file_path.endswith(".csv"):
            text = extract_text_from_csv(file_path)
        elif file_path.endswith(".pdf"):
            text = extract_text_from_pdf(file_path)
        elif file_path.endswith(".md"):  # âœ… Markdown íŒŒì¼ ì²˜ë¦¬
            text = extract_text_from_md(file_path)
        else:
            continue

        if text and isinstance(text, str) and len(text.strip()) > 20 and not pd.isna(text) and not isinstance(text, float):
            embedding = embedding_model.encode(text).tolist()
            collection.add(
                ids=[doc_id],
                embeddings=[embedding],
                documents=[text],  # âœ… ì›ë³¸ í…ìŠ¤íŠ¸ ì €ì¥
                metadatas=[{"source": file_path}]
            )
            print(f"âœ… Embedded {file_path}")
        else:
            print(f"âš ï¸ Skipping {file_path} (text too short or None)")


# âœ… ì‹¤í–‰
# collection.delete()  # ëª¨ë“  ë°ì´í„° ì‚­ì œ
# print("ğŸš€ ChromaDB ëª¨ë“  ë°ì´í„° ì‚­ì œ ì™„ë£Œ!")

# âœ… ë°ì´í„° ì¬ì‚½ì… ì‹¤í–‰
embed_documents()
print("âœ… ë°ì´í„° ì¬í•™ìŠµ ì™„ë£Œ!")
print("collection count: " + str(collection.count()))
# print("sample_documents below")
# print(str(collection.peek(limit=1)))
